{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johannesmichael/AMLD/blob/main/01_Intro_to_environment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hm9T3KjCYlwk"
      },
      "source": [
        "Setup\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRhzlYGRYlwq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1bd7a01-7c8c-4394-d1ae-cc6ec42ec308"
      },
      "source": [
        "  import sys\n",
        "\n",
        "  # Setup for use in Colab\n",
        "  if 'google.colab' in sys.modules:\n",
        "      # Clone GitHub repository\n",
        "      !git clone https://github.com/AIcrowd/droneRL-workshop\n",
        "\n",
        "      # Install packages via pip\n",
        "      !pip install -r \"droneRL-workshop/colab-requirements.txt\"\n",
        "\n",
        "      # Restart Runtime so everything takes effect\n",
        "      import os\n",
        "      os.kill(os.getpid(), 9)\n",
        "\n",
        "      # Your Runtime will crash after this - this is normal!\n",
        "      # Resume from next cell after it restarted"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'droneRL-workshop'...\n",
            "remote: Enumerating objects: 648, done.\u001b[K\n",
            "remote: Counting objects: 100% (105/105), done.\u001b[K\n",
            "remote: Compressing objects: 100% (82/82), done.\u001b[K\n",
            "remote: Total 648 (delta 49), reused 61 (delta 19), pack-reused 543\u001b[K\n",
            "Receiving objects: 100% (648/648), 15.03 MiB | 14.01 MiB/s, done.\n",
            "Resolving deltas: 100% (375/375), done.\n",
            "Collecting gym==0.15.4\n",
            "  Downloading gym-0.15.4.tar.gz (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 5.1 MB/s \n",
            "\u001b[?25hCollecting Pillow==6.2.2\n",
            "  Downloading Pillow-6.2.2-cp37-cp37m-manylinux1_x86_64.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 31.8 MB/s \n",
            "\u001b[?25hCollecting tqdm==4.41.1\n",
            "  Downloading tqdm-4.41.1-py2.py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.0 MB/s \n",
            "\u001b[?25hCollecting seaborn==0.9.1\n",
            "  Downloading seaborn-0.9.1-py2.py3-none-any.whl (216 kB)\n",
            "\u001b[K     |████████████████████████████████| 216 kB 41.4 MB/s \n",
            "\u001b[?25hCollecting matplotlib==3.1.2\n",
            "  Downloading matplotlib-3.1.2-cp37-cp37m-manylinux1_x86_64.whl (13.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.1 MB 73 kB/s \n",
            "\u001b[?25hCollecting pandas==0.25.3\n",
            "  Downloading pandas-0.25.3-cp37-cp37m-manylinux1_x86_64.whl (10.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4 MB 107 kB/s \n",
            "\u001b[?25hRequirement already satisfied: moviepy==0.2.3.5 in /usr/local/lib/python3.7/dist-packages (from -r droneRL-workshop/colab-requirements.txt (line 7)) (0.2.3.5)\n",
            "Collecting numpy==1.17.5\n",
            "  Downloading numpy-1.17.5-cp37-cp37m-manylinux1_x86_64.whl (20.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 20.0 MB 6.4 MB/s \n",
            "\u001b[?25hCollecting torch==1.4.0\n",
            "  Downloading torch-1.4.0-cp37-cp37m-manylinux1_x86_64.whl (753.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 753.4 MB 5.7 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.5.0\n",
            "  Downloading torchvision-0.5.0-cp37-cp37m-manylinux1_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 43.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym==0.15.4->-r droneRL-workshop/colab-requirements.txt (line 1)) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gym==0.15.4->-r droneRL-workshop/colab-requirements.txt (line 1)) (1.15.0)\n",
            "Collecting pyglet<=1.3.2,>=1.2.0\n",
            "  Downloading pyglet-1.3.2-py2.py3-none-any.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 64.2 MB/s \n",
            "\u001b[?25hCollecting cloudpickle~=1.2.0\n",
            "  Downloading cloudpickle-1.2.2-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from gym==0.15.4->-r droneRL-workshop/colab-requirements.txt (line 1)) (4.1.2.30)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.2->-r droneRL-workshop/colab-requirements.txt (line 5)) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.2->-r droneRL-workshop/colab-requirements.txt (line 5)) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.2->-r droneRL-workshop/colab-requirements.txt (line 5)) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.2->-r droneRL-workshop/colab-requirements.txt (line 5)) (0.10.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas==0.25.3->-r droneRL-workshop/colab-requirements.txt (line 6)) (2018.9)\n",
            "Requirement already satisfied: imageio<3.0,>=2.1.2 in /usr/local/lib/python3.7/dist-packages (from moviepy==0.2.3.5->-r droneRL-workshop/colab-requirements.txt (line 7)) (2.4.1)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.7/dist-packages (from moviepy==0.2.3.5->-r droneRL-workshop/colab-requirements.txt (line 7)) (4.4.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.3.2,>=1.2.0->gym==0.15.4->-r droneRL-workshop/colab-requirements.txt (line 1)) (0.16.0)\n",
            "Building wheels for collected packages: gym\n",
            "  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.15.4-py3-none-any.whl size=1648483 sha256=abfe6024c26270f398303baa4e69566dd7ede5c84ebb84aef784f5734d8c603b\n",
            "  Stored in directory: /root/.cache/pip/wheels/27/97/51/3adbfe67f40bce89b8eba2d3b8f42ec1c9f9c1e6305a73510d\n",
            "Successfully built gym\n",
            "Installing collected packages: Pillow, numpy, tqdm, torch, pyglet, pandas, matplotlib, cloudpickle, torchvision, seaborn, gym\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.62.3\n",
            "    Uninstalling tqdm-4.62.3:\n",
            "      Successfully uninstalled tqdm-4.62.3\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.9.0+cu102\n",
            "    Uninstalling torch-1.9.0+cu102:\n",
            "      Successfully uninstalled torch-1.9.0+cu102\n",
            "  Attempting uninstall: pyglet\n",
            "    Found existing installation: pyglet 1.5.0\n",
            "    Uninstalling pyglet-1.5.0:\n",
            "      Successfully uninstalled pyglet-1.5.0\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.1.5\n",
            "    Uninstalling pandas-1.1.5:\n",
            "      Successfully uninstalled pandas-1.1.5\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 1.3.0\n",
            "    Uninstalling cloudpickle-1.3.0:\n",
            "      Successfully uninstalled cloudpickle-1.3.0\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.10.0+cu102\n",
            "    Uninstalling torchvision-0.10.0+cu102:\n",
            "      Successfully uninstalled torchvision-0.10.0+cu102\n",
            "  Attempting uninstall: seaborn\n",
            "    Found existing installation: seaborn 0.11.2\n",
            "    Uninstalling seaborn-0.11.2:\n",
            "      Successfully uninstalled seaborn-0.11.2\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.17.3\n",
            "    Uninstalling gym-0.17.3:\n",
            "      Successfully uninstalled gym-0.17.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray 0.18.2 requires pandas>=1.0, but you have pandas 0.25.3 which is incompatible.\n",
            "torchtext 0.10.0 requires torch==1.9.0, but you have torch 1.4.0 which is incompatible.\n",
            "tensorflow 2.6.0 requires numpy~=1.19.2, but you have numpy 1.17.5 which is incompatible.\n",
            "tensorflow-probability 0.13.0 requires cloudpickle>=1.3, but you have cloudpickle 1.2.2 which is incompatible.\n",
            "panel 0.12.1 requires tqdm>=4.48.0, but you have tqdm 4.41.1 which is incompatible.\n",
            "kapre 0.3.5 requires numpy>=1.18.5, but you have numpy 1.17.5 which is incompatible.\n",
            "jaxlib 0.1.71+cuda111 requires numpy>=1.18, but you have numpy 1.17.5 which is incompatible.\n",
            "jax 0.2.21 requires numpy>=1.18, but you have numpy 1.17.5 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas~=1.1.0; python_version >= \"3.0\", but you have pandas 0.25.3 which is incompatible.\n",
            "fbprophet 0.7.1 requires pandas>=1.0.4, but you have pandas 0.25.3 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "bokeh 2.3.3 requires pillow>=7.1.0, but you have pillow 6.2.2 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed Pillow-6.2.2 cloudpickle-1.2.2 gym-0.15.4 matplotlib-3.1.2 numpy-1.17.5 pandas-0.25.3 pyglet-1.3.2 seaborn-0.9.1 torch-1.4.0 torchvision-0.5.0 tqdm-4.41.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYJ-heIaiDxn"
      },
      "source": [
        "%cd droneRL-workshop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYzA28d3Ylw0"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "from IPython.lib.pretty import pretty"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98z39n0UYlw3"
      },
      "source": [
        "The challenge environment\n",
        "---\n",
        "\n",
        "The environment for this challenge is called **`DeliveryDrones`**.\n",
        "\n",
        "After creating the environment, call `reset()` to initalize the environment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkHZJ1oNYlw4"
      },
      "source": [
        "from env.env import DeliveryDrones\n",
        "\n",
        "# Create environment\n",
        "env = DeliveryDrones()\n",
        "\n",
        "# Resets it and get the initial observation\n",
        "observation = env.reset()\n",
        "\n",
        "# Render in text\n",
        "print(env.render(mode='ansi'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8wHU95VYlw6"
      },
      "source": [
        "# Render as an RGB image to see things more clearly\n",
        "Image.fromarray(env.render(mode='rgb_array'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8HdUGT9Ylw9"
      },
      "source": [
        "Observations spaces\n",
        "---\n",
        "\n",
        "By default, the environment returns `ground` and `air` grids as observations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0O6wFz1Ylw-"
      },
      "source": [
        "# Observations are returned after env.reset() or env.step() calls\n",
        "print(observation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_9uZ7V6YlxB"
      },
      "source": [
        "# We can inspect what's on the ground\n",
        "observation['ground'].grid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snCDOXVzYlxE"
      },
      "source": [
        "We use **observation wrappers** to produce states that can be used with RL agents."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-V8dcm6mYlxF"
      },
      "source": [
        "from env.wrappers import CompassQTable, CompassChargeQTable, LidarCompassQTable, LidarCompassChargeQTable\n",
        "\n",
        "# Create the environment\n",
        "env = DeliveryDrones()\n",
        "\n",
        "# Use an observation wrappers\n",
        "#env = CompassQTable(env)\n",
        "#env = CompassChargeQTable(env)\n",
        "env = LidarCompassQTable(env)\n",
        "#env = LidarCompassChargeQTable(env)\n",
        "\n",
        "# Reset the environment and print inital observation\n",
        "observation = env.reset()\n",
        "print(pretty(observation))\n",
        "\n",
        "# Render as an RGB image\n",
        "Image.fromarray(env.render(mode='rgb_array'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHfy5B0xYlxH"
      },
      "source": [
        "# Print the state in a nicer way using `env.format_state`\n",
        "{drone: env.format_state(observation) for drone, observation in observation.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiuXEgUWvJbc"
      },
      "source": [
        "## Manually controlling a drone"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqyxUJAHsuMT"
      },
      "source": [
        "from env.env import Action\n",
        "\n",
        "Action??"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQJpDbt4s0y3"
      },
      "source": [
        "observation, reward, done, info = env.step({0: Action.RIGHT})\n",
        "\n",
        "print('Reward: {}'.format(reward))\n",
        "print('Done: {}'.format(done))\n",
        "Image.fromarray(env.render(mode='rgb_array'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfBLPP08uKCC"
      },
      "source": [
        "{drone: env.format_state(observation) for drone, observation in observation.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1W9xJXZYlxJ"
      },
      "source": [
        "The `WindowedGridView` observation wrapper\n",
        "---\n",
        "\n",
        "This is the \"official\" wrapper for the competition!\n",
        "\n",
        "```\n",
        "Observation wrapper: (N, N, 6) numerical arrays with location of\n",
        "(0) drones         marked with                   1 / 0 otherwise\n",
        "(1) packets        marked with                   1 / 0 otherwise\n",
        "(2) dropzones      marked with                   1 / 0 otherwise\n",
        "(3) stations       marked with                   1 / 0 otherwise\n",
        "(4) drones charge  marked with   charge level 0..1 / 0 otherwise\n",
        "(5) obstacles      marked with                   1 / 0 otherwise\n",
        "Where N is the size of the window, i the number of drones\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8692JPAYlxK"
      },
      "source": [
        "from env.wrappers import WindowedGridView\n",
        "\n",
        "env = WindowedGridView(DeliveryDrones(), radius=3)\n",
        "states = env.reset()\n",
        "Image.fromarray(env.render(mode='rgb_array'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWQA7MGLYlxN"
      },
      "source": [
        "{drone: env.format_state(state) for drone, state in states.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUkzpIBaYlxS"
      },
      "source": [
        "states[0][:, :, 5] # Obstacles from the perspective of drone 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lIIDZmWYlxV"
      },
      "source": [
        "Create and run agents\n",
        "---\n",
        "\n",
        "After creating your agents, you can run them with the `test_agents()` method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rAR78sQYlxV"
      },
      "source": [
        "from agents.random import RandomAgent\n",
        "\n",
        "# Create and setup the environment\n",
        "env = WindowedGridView(DeliveryDrones(), radius=3)\n",
        "states = env.reset()\n",
        "\n",
        "# Create random agents\n",
        "agents = {drone.index: RandomAgent(env) for drone in env.drones}\n",
        "agents"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e30M9h3YYlxY"
      },
      "source": [
        "from helpers.rl_helpers import test_agents\n",
        "\n",
        "# Run agents for 1000 steps\n",
        "rewards_log = test_agents(env, agents, n_steps=1000, seed=0)\n",
        "\n",
        "# Print rewards\n",
        "for drone_index, rewards in rewards_log.items():\n",
        "    print('Drone {} rewards: {} ..'.format(drone_index, rewards[:10]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYpyGMMTYlxa"
      },
      "source": [
        "And visualize the rewards with the helpers functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHZoRdk6Ylxa"
      },
      "source": [
        "from helpers.rl_helpers import plot_cumulative_rewards\n",
        "\n",
        "plot_cumulative_rewards(\n",
        "    rewards_log,\n",
        "    events={'pickup': [1], 'crash': [-1]}, # Optional, default: pickup/crash ±1\n",
        "    drones_labels={0: 'My drone'}, # Optional, default: drone index\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWF3mrreYlxd"
      },
      "source": [
        "Train a first agent\n",
        "---\n",
        "\n",
        "To train your agents, you will use the `MultiAgentTrainer()`.\n",
        "\n",
        "You will train a first DQN agent, that you will learn more about soon."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ii8G6rDAYlxd"
      },
      "source": [
        "from agents.dqn import DQNAgent, DenseQNetworkFactory\n",
        "from helpers.rl_helpers import MultiAgentTrainer, plot_rolling_rewards\n",
        "\n",
        "# Create and setup the environment\n",
        "env = WindowedGridView(DeliveryDrones(), radius=3)\n",
        "env.env_params.update({'n_drones': 3, 'skyscrapers_factor': 0, 'charge_reward': 0, 'discharge': 0})\n",
        "states = env.reset()\n",
        "\n",
        "# Create random agents\n",
        "agents = {drone.index: RandomAgent(env) for drone in env.drones}\n",
        "\n",
        "# Use a DQNAgent for agent 0 - we will see how this works next\n",
        "agents[0] = DQNAgent(\n",
        "    env, DenseQNetworkFactory(env, hidden_layers=[32, 32]),\n",
        "    gamma=0.95, epsilon_start=1.0, epsilon_decay=0.999, epsilon_end=0.01,\n",
        "    memory_size=10000, batch_size=64, target_update_interval=5\n",
        ")\n",
        "\n",
        "agents"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NMgWWBVdLim"
      },
      "source": [
        "RandomAgent??"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXh-nDjPYlxh"
      },
      "source": [
        "# Create trainer\n",
        "trainer = MultiAgentTrainer(env, agents, reset_agents=True, seed=0)\n",
        "\n",
        "# Train with different grids\n",
        "trainer.train(1000)\n",
        "\n",
        "# Print rewards\n",
        "for drone_index, rewards in trainer.rewards_log.items():\n",
        "    print('Drone {} rewards: {} ..'.format(drone_index, rewards[:10]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9dXK8JbYlxk"
      },
      "source": [
        "And visualize training with helpers functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NBBCTvHYlxl"
      },
      "source": [
        "plot_rolling_rewards(\n",
        "    trainer.rewards_log,\n",
        "    drones_labels={0: 'My drone'}, # Optional: specify drone names\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7UwlPG5Ylxn"
      },
      "source": [
        "Test agents\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZ0XiT3aYlxo"
      },
      "source": [
        "rewards_log = test_agents(env, agents, n_steps=1000, seed=1)\n",
        "plot_cumulative_rewards(rewards_log, drones_labels={0: 'My drone'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LUB3n6RYlxq"
      },
      "source": [
        "Visualize a \"run\"\n",
        "---\n",
        "\n",
        "Share videos of your best agents! `#desiRL` `#droneRL`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OopF87pKYlxr"
      },
      "source": [
        "from helpers.rl_helpers import render_video, ColabVideo\n",
        "\n",
        "path = os.path.join('output', 'videos', 'intro-run.mp4')\n",
        "render_video(env, agents, video_path=path, n_steps=120, fps=1, seed=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A65R8PA1Ylxt"
      },
      "source": [
        "# Display the video in the notebook\n",
        "ColabVideo(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Yts898voWHN"
      },
      "source": [
        "## Submit to AIcrowd! 🚀"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dDLEqc1oZbV"
      },
      "source": [
        "path = os.path.join('output', 'agents', 'first-agent.pt')\n",
        "agents[0].save(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYpacPiJoo4t"
      },
      "source": [
        "Download the file `droneRL-workshop/output/agents/first-agent.pt` then submit it\n",
        "\n",
        "> https://www.aicrowd.com/challenges/dronerl"
      ]
    }
  ]
}